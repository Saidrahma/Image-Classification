{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: \n",
    "# Image Classification Model: Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph of deps:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Examining @/win-64::__cuda==9.1=0:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Examining keras:  33%|###3      | 1/3 [00:00<?, ?it/s]                  \n",
      "Examining python=3.8:  67%|######6   | 2/3 [00:01<00:00,  1.51it/s]\n",
      "Examining python=3.8: 100%|##########| 3/3 [00:01<00:00,  2.27it/s]\n",
      "                                                                   \n",
      "\n",
      "Determining conflicts:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Examining conflict for __cuda:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Examining conflict for keras python:  33%|###3      | 1/3 [00:00<?, ?it/s]\n",
      "                                                                          \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - keras -> python[version='>=3.5,<3.6.0a0|>=3.6,<3.7.0a0']\n",
      "\n",
      "Your python: python=3.8\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "The following specifications were found to be incompatible with your system:\n",
      "\n",
      "  - feature:/win-64::__cuda==9.1=0\n",
      "\n",
      "Your installed version is: 9.1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n"
     ]
    }
   ],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4c1209da645c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cf776ff100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "im = Image.open(\"data/testing/0/346.jpg\")\n",
    "im = np.array(im)\n",
    "print(\"Image Shape:\", im.shape)\n",
    "plt.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better. In Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class. This class allows you to:\n",
    "\n",
    "- configure random transformations and normalization operations to be done on your image data during training\n",
    "- instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255, # is a value by which we will multiply the data before any other processing\n",
    "                                  shear_range=0.2, #is for randomly applying shearing transformations\n",
    "                                  zoom_range=0.2, #is for randomly zooming inside pictures\n",
    "                                  horizontal_flip=True, #is for randomly flipping half of the images horizontally\n",
    "                                  rotation_range=40, #is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "                                  width_shift_range=0.2, #which to randomly translate pictures vertically or horizontally\n",
    "                                  height_shift_range=0.2, \n",
    "                                  fill_mode='nearest' #is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "                                 )\n",
    "\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\"data/testing\", batch_size=1, \n",
    "                                                        class_mode='categorical', \n",
    "                                                        color_mode='grayscale', \n",
    "                                                        target_size=(28,28)\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in validation_generator:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    plt.imshow(x[0,:,:,0], cmap='gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictclass = validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictclass['5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Object Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Classifier():\n",
    "    def __init__(self, train_folder='data/train', validation_folder='data/validation', \n",
    "                  inshape=(28,28,1), num_classes=10, num_train=1000, num_validation=200):\n",
    "        self.train_folder = train_folder\n",
    "        self.validation_folder =  validation_folder\n",
    "        self.inshape = inshape\n",
    "    \n",
    "        self.num_classes = num_classes\n",
    "        self.num_train = num_train\n",
    "        self.num_validation = num_validation\n",
    "        \n",
    "    def model(self, inshape=(28,28,1), num_classes=10, learning_rate=0.001):\n",
    "        '''\n",
    "            Three steps to Convolution\n",
    "                1. Convolution\n",
    "                2. Activation\n",
    "                3. Polling\n",
    "            Repeat Steps 1,2,3 for adding more hidden layers\n",
    "                4. After that make a fully connected network\n",
    "            This fully connected network gives ability to the CNN\n",
    "            to classify the samples\n",
    "        '''\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', \n",
    "                         kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "                         input_shape=inshape, data_format=\"channels_last\"))\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', \n",
    "                         kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "    \n",
    "        model.add(Dropout(rate=0.8)) # rate: rate of nodes to be keeped\n",
    "\n",
    "        model.add(Dense(units=512, activation='relu'))\n",
    "        \n",
    "        model.add(Dropout(rate=0.8))\n",
    "\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        # Binary cross-entropy is for multi-label classifications, whereas categorical cross entropy is for multi-class classification where each example belongs to a single class.\n",
    "        optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, batch_size=128, epochs=12, learning_rate=0.001, model_file=\"my_model.h5\", refine = False):\n",
    "        '''\n",
    "            Train Process\n",
    "        '''\n",
    "        # this is the augmentation configuration we will use for training\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, # is a value by which we will multiply the data before any other processing\n",
    "                                            shear_range=0.2, #is for randomly applying shearing transformations\n",
    "                                            zoom_range=0.2, #is for randomly zooming inside pictures\n",
    "                                            horizontal_flip=True, #is for randomly flipping half of the images horizontally\n",
    "                                            #rotation_range=40, #is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "                                            #width_shift_range=0.2, #which to randomly translate pictures vertically or horizontally\n",
    "                                            #height_shift_range=0.2, \n",
    "                                            #fill_mode='nearest' #is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "                                          )\n",
    "\n",
    "        # this is the augmentation configuration we will use for testing:\n",
    "        # only rescaling\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # this is a generator that will read pictures found in\n",
    "        # subfolers of 'data/train', and indefinitely generate\n",
    "        # batches of augmented image data\n",
    "        train_generator = train_datagen.flow_from_directory(self.train_folder,  # this is the target directory\n",
    "                                                            target_size=(28,28),  # all images will be resized to 150x150\n",
    "                                                            batch_size=batch_size, \n",
    "                                                            color_mode='grayscale',\n",
    "                                                            #class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "                                                           )\n",
    "        # this is a similar generator, for validation data\n",
    "        validation_generator = test_datagen.flow_from_directory(self.validation_folder, \n",
    "                                                                target_size=(28,28),\n",
    "                                                                batch_size=batch_size, \n",
    "                                                                color_mode='grayscale',\n",
    "                                                                #class_mode='binary'\n",
    "                                                               )\n",
    "        if refine:\n",
    "            model = load_model(model_file)\n",
    "        else:\n",
    "            model = self.model(inshape=self.inshape, num_classes=self.num_classes, learning_rate=learning_rate)\n",
    "        \n",
    "        ts = time.time()\n",
    "        tbCallBack = TensorBoard(log_dir='./logs/' + str(ts), histogram_freq=0, write_graph=True, write_images=True)\n",
    "        \n",
    "        # To launch tensorbord\n",
    "        # tensorboard --logdir ./logs\n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=self.num_train // batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=self.num_validation // batch_size,\n",
    "                            callbacks=[tbCallBack])\n",
    "        \n",
    "        # You can use model.save(filepath) to save a Keras model into a single HDF5 file which will contain:\n",
    "        # 1- the architecture of the model, allowing to re-create the model\n",
    "        # 2- the weights of the model\n",
    "        # 3- the training configuration (loss, optimizer)\n",
    "        # 4- the state of the optimizer, allowing to resume training exactly where you left off.\n",
    "\n",
    "        model.save(model_file)\n",
    "        \n",
    "        \n",
    "    def predict(self, x, model_file=\"my_model.h5\"):\n",
    "        model = load_model(model_file)\n",
    "        prediction = model.predict(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_classifier = Image_Classifier(train_folder = 'data/training', \n",
    "                                 validation_folder = 'data/testing', \n",
    "                                 inshape=(28,28,1), num_classes=10,\n",
    "                                 num_train=60000, num_validation=1000)\n",
    "\n",
    "im_classifier.train(batch_size=128, epochs=12, learning_rate=0.001)\n",
    "# im_classifier.train(batch_size=128, epochs=20, learning_rate=0.0001, refine=True, model_file=\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"data/testing/6/870.jpg\")\n",
    "im = np.array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = np.expand_dims(im, axis=3)\n",
    "print(im.shape)\n",
    "im_classifier = Image_Classifier()\n",
    "prediction = im_classifier.predict(im, model_file=\"my_model.h5\")\n",
    "prediction_digit = prediction[0].argmax()\n",
    "print(\"The corresponding image digit is :\", prediction_digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
